# Introduction to Machine Learning

In this course, I, [Milda Poceviciute](https://github.com/poceviciute) and [Henrik Karlsson](https://github.com/henkar91) had 5 lab projects that we had to implement everything in R programming language. Group members were supposed to do each lab own their own and at the end put entire work into a report by choosing best explanations. We have implemented some algorithms to solve a wide variety of machine learning problems. Sometimes we used packages but played with their parameters to understand problems.

## What I learned from this course?

I have learned so much things in this course, so I will write down everything which I think it is useful. It is also helpful to remind me whenever I need.

### ===> [Lab 1](ML_Lab1_Group/)
In this lab, we were asked to solve 3 assignments, which are about K-NN Algorithm, Cross Validation, Linear Regression and Regularization.

#### Assignment 1
- Implemented K-NN algorithm to achieve our goal. 
- Tried different K parameters and compared misclassification rates.
- Tried kknn() package for same purpose and compared result with previous steps.
- Analyzed ROC curves and sensitivity and specifity.

#### Assignment 3
- Feature selection (best subset selection) in linear regression by using k-fold cross-validation

#### Assignment 4
- Bias-variance tradeoff investigation with MSE
- stepAIC usage.
- Ridge regression
- LASSO model with optimal \lambda using cross validation

### ===> [Lab 2](ML_Lab2_Group/)
In this lab, we were asked to solve 3 assignments, which are about LDA, Logistic Regression, Deviance-Gini Index comparison, Decision Trees, Naive Bayes, Confidence band for decision tree, non-parametric bootstrap, parametric bootstrap.

#### Assignment 1
- Decision boundary analysis to use LDA
- LDA vs Logistic Regression comparison

#### Assignment 2
- Deviance and Gini index comparison for evaluation
- Finding ptimal Decision Tree depth
- Appliyng Naive Bayes algorithm
- Comparison confusion matrices for all algorithms which are used.

#### Assignment 3
- Applied decision tree with cross-validation.
- Computeed 95% confidence band for both non-parametric and parametric bootstrap
- Result evaluation.

### ===> [Lab 1 Block 2](ML_Lab1_Block2_Group/)
In this lab, we were asked to solve 2 assignments, which are about Ensemble Methods and Expectation Maximization algorithms

#### Assignment 1
- Adaboost and Random Forest algorithms comparison with number of trees from 10 to 100.

#### Assignment 2
- Implemented EM algorithm for mixtures of multivariate Benouilli distributions.

## Labs

[Lab 1](ML_Lab1_Group/)

- a


[Lab 2](ML_Lab2_Group/)

- a


[Lab 1 Block 2](ML_Lab1_Block2_Group/)

- a


[Lab 2 Block 2](ML_Lab2_Block2_Group/)

- a


[Lab 3 Block 1](ML_Lab3_Block1_Group/)

- a
